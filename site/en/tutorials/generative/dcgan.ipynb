{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jQ1tEQCxwRx"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "V_sgB_5dx1f1"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TD5ZrvEMbhZ"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/dcgan\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/generative/dcgan.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITZuApL56Mny"
      },
      "source": [
        "This tutorial demonstrates how to generate images of handwritten digits using a [Deep Convolutional Generative Adversarial Network](https://arxiv.org/pdf/1511.06434.pdf) (DCGAN). The code is written using the [Keras Sequential API](https://www.tensorflow.org/guide/keras) with a `tf.GradientTape` training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MbKJY38Puy9"
      },
      "source": [
        "## What are GANs?\n",
        "[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GANs) are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A *generator* (\"the artist\") learns to create images that look real, while a *discriminator* (\"the art critic\") learns to tell real images apart from fakes.\n",
        "\n",
        "![A diagram of a generator and discriminator](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gan1.png?raw=1)\n",
        "\n",
        "During training, the *generator* progressively becomes better at creating images that look real, while the *discriminator* becomes better at telling them apart. The process reaches equilibrium when the *discriminator* can no longer distinguish real images from fakes.\n",
        "\n",
        "![A second diagram of a generator and discriminator](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gan2.png?raw=1)\n",
        "\n",
        "This notebook demonstrates this process on the MNIST dataset. The following animation shows a series of images produced by the *generator* as it was trained for 50 epochs. The images begin as random noise, and increasingly resemble hand written digits over time.\n",
        "\n",
        "![sample output](https://tensorflow.org/images/gan/dcgan.gif)\n",
        "\n",
        "To learn more about GANs, see MIT's [Intro to Deep Learning](http://introtodeeplearning.com/) course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WZKbyU2-AiY-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wx-zNbLqB4K8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d9e1ef6-2fb2-48e7-e8ed-06c2682d1ebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YzTlj4YdCip_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cee4ab-b1a9-4bbd-92cf-33f620e05fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-0bttxkv1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-0bttxkv1\n",
            "  Resolved https://github.com/tensorflow/docs to commit abfbe6e54864baa38dbb985b984acd304be610d4\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.8.0)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.3.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (23.1.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (3.3.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=183273 sha256=2c59a0b9f0db6c00b364f4b9112d3de2883711d26db292bbdaabc1f38a3c6a90\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-99me8p43/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ],
      "source": [
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "You will use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a4fYMGxGhrna"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "id": "_OaGWxts4H-3",
        "outputId": "ab60fa52-5aaa-47d4-a573-4d3c73509a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "Bo6Yriz32GJb",
        "outputId": "a560e871-a04e-4925-93a3-08be96719e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0]"
      ],
      "metadata": {
        "id": "VT_AZ85q1FdW",
        "outputId": "61d08a73-cc96-4cab-da5d-f0acc0b9274a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_images[0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZJjqcS5u2OoL",
        "outputId": "c35085f1-a81e-402b-d7bf-eeca7c58beaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NFC2ghIdiZYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946a90b3-893b-4c9b-882b-5342a944ff57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  3.],\n",
              "        [ 18.],\n",
              "        [ 18.],\n",
              "        [ 18.],\n",
              "        [126.],\n",
              "        [136.],\n",
              "        [175.],\n",
              "        [ 26.],\n",
              "        [166.],\n",
              "        [255.],\n",
              "        [247.],\n",
              "        [127.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 30.],\n",
              "        [ 36.],\n",
              "        [ 94.],\n",
              "        [154.],\n",
              "        [170.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [225.],\n",
              "        [172.],\n",
              "        [253.],\n",
              "        [242.],\n",
              "        [195.],\n",
              "        [ 64.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 49.],\n",
              "        [238.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [251.],\n",
              "        [ 93.],\n",
              "        [ 82.],\n",
              "        [ 82.],\n",
              "        [ 56.],\n",
              "        [ 39.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 18.],\n",
              "        [219.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [198.],\n",
              "        [182.],\n",
              "        [247.],\n",
              "        [241.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 80.],\n",
              "        [156.],\n",
              "        [107.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [205.],\n",
              "        [ 11.],\n",
              "        [  0.],\n",
              "        [ 43.],\n",
              "        [154.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 14.],\n",
              "        [  1.],\n",
              "        [154.],\n",
              "        [253.],\n",
              "        [ 90.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [139.],\n",
              "        [253.],\n",
              "        [190.],\n",
              "        [  2.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 11.],\n",
              "        [190.],\n",
              "        [253.],\n",
              "        [ 70.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 35.],\n",
              "        [241.],\n",
              "        [225.],\n",
              "        [160.],\n",
              "        [108.],\n",
              "        [  1.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 81.],\n",
              "        [240.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [119.],\n",
              "        [ 25.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 45.],\n",
              "        [186.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [150.],\n",
              "        [ 27.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 16.],\n",
              "        [ 93.],\n",
              "        [252.],\n",
              "        [253.],\n",
              "        [187.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [249.],\n",
              "        [253.],\n",
              "        [249.],\n",
              "        [ 64.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 46.],\n",
              "        [130.],\n",
              "        [183.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [207.],\n",
              "        [  2.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 39.],\n",
              "        [148.],\n",
              "        [229.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [250.],\n",
              "        [182.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 24.],\n",
              "        [114.],\n",
              "        [221.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [201.],\n",
              "        [ 78.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 23.],\n",
              "        [ 66.],\n",
              "        [213.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [198.],\n",
              "        [ 81.],\n",
              "        [  2.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 18.],\n",
              "        [171.],\n",
              "        [219.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [195.],\n",
              "        [ 80.],\n",
              "        [  9.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [ 55.],\n",
              "        [172.],\n",
              "        [226.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [244.],\n",
              "        [133.],\n",
              "        [ 11.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [136.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [253.],\n",
              "        [212.],\n",
              "        [135.],\n",
              "        [132.],\n",
              "        [ 16.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]],\n",
              "\n",
              "       [[  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.],\n",
              "        [  0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ],
      "metadata": {
        "id": "fH4VGdFA5WUr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0]"
      ],
      "metadata": {
        "id": "SbTOVup65PUr",
        "outputId": "d2b38df0-2543-4778-e86b-4fde119531c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UGN3dIJS3u6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "S4PIDhoDLbsZ"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-yKCCQOoJ7cn"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_dataset.take(5)):\n",
        "    print(f\"Lote {i+1}: {batch.shape}\")\n",
        "    print(f\"Primeros 10 valores de la imagen: {batch[:100, :100, 0]}\")"
      ],
      "metadata": {
        "id": "bdC6ONJ03LQw",
        "outputId": "0f8e51b3-92bd-4468-c792-6052a68f2cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lote 1: (256, 28, 28, 1)\n",
            "Primeros 10 valores de la imagen: [[[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]]\n",
            "Lote 2: (256, 28, 28, 1)\n",
            "Primeros 10 valores de la imagen: [[[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]]\n",
            "Lote 3: (256, 28, 28, 1)\n",
            "Primeros 10 valores de la imagen: [[[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]]\n",
            "Lote 4: (256, 28, 28, 1)\n",
            "Primeros 10 valores de la imagen: [[[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]]\n",
            "Lote 5: (256, 28, 28, 1)\n",
            "Primeros 10 valores de la imagen: [[[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[-1.]\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  ...\n",
            "  [-1.]\n",
            "  [-1.]\n",
            "  [-1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Yz_PIMw_Imd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Create the models\n",
        "\n",
        "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### The Generator\n",
        "\n",
        "The generator uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a `Dense` layer that takes this seed as input, then upsample several times until you reach the desired image size of 28x28x1. Notice the `tf.keras.layers.LeakyReLU` activation for each layer, except the output layer which uses tanh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6bpTcDqoLWjY"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyWgG09LCSJl"
      },
      "source": [
        "Use the (as yet untrained) generator to create an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gl7jcC7TdPTG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "d0db058a-7a38-40bb-e4ba-0eb856e0f7bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f15083ec370>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### The Discriminator\n",
        "\n",
        "The discriminator is a CNN-based image classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw2tPLmk2pEP"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPneagzCaQv"
      },
      "source": [
        "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkA05NE6QMs"
      },
      "outputs": [],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss and optimizers\n",
        "\n",
        "Define loss functions and optimizers for both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psQfmXxYKU3X"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "### Discriminator loss\n",
        "\n",
        "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "### Generator loss\n",
        "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "The discriminator and the generator optimizers are different since you will train two networks separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWtinsGDPJlV"
      },
      "source": [
        "### Save checkpoints\n",
        "This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA1w-7s2POEy"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Define the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jylSonrqSWfi"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5ibNo05jCB"
      },
      "outputs": [],
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M7LmLtGEMQJ"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generate and save images**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Train the model\n",
        "Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
        "\n",
        "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly3UN0SLLY2l"
      },
      "outputs": [],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfM4YcPVPkNO"
      },
      "source": [
        "Restore the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhXsd0srPo8c"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "## Create a GIF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfO5wCdclHGL"
      },
      "outputs": [],
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x3q9_Oe5q0A"
      },
      "outputs": [],
      "source": [
        "display_image(EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "Use `imageio` to create an animated gif using the images saved during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGKQgENQ8lEI"
      },
      "outputs": [],
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBwyU6t2Wf3g"
      },
      "outputs": [],
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6qC-SbjK0yW"
      },
      "source": [
        "## Next steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjjkT9KAK6H7"
      },
      "source": [
        "This tutorial has shown the complete code necessary to write and train a GAN. As a next step, you might like to experiment with a different dataset, for example the Large-scale Celeb Faces Attributes (CelebA) dataset [available on Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset). To learn more about GANs see the [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dcgan.ipynb",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}